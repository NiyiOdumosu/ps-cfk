apiVersion: platform.confluent.io/v1beta1
kind: Connector
metadata:
  name: oracdc001
spec:
#  class: io.confluent.connect.oracle.cdc.OracleCdcSourceConnector - class path
#  class: OracleCdcSourceConnector - alias
  class: OracleCdcSource
  restartPolicy:
    type: OnFailure

  configs:
    key.converter: io.confluent.connect.avro.AvroConverter
    value.converter: io.confluent.connect.avro.AvroConverter
    oracle.server: oracle-svc.oracle.svc.cluster.local
    oracle.port: "1521"
    oracle.sid: ORCLCDB
    oracle.pdb.name: ORCLPDB1
    oracle.username: C##MYUSER
    oracle.password: mypassword
    oracle.date.mapping: timestamp
    oracle.validation.result.fetch.size: "5000"
    heartbeat.interval.ms: "3000"
    heartbeat.topic.name: ${connectorName}-${databaseName}-heartbeat-topic
    redo.log.consumer.bootstrap.servers: kafka:9073
    redo.log.consumer.security.protocol: SASL_SSL
    redo.log.consumer.ssl.truststore.location: /mnt/sslcerts/tls-connect/truststore.p12
    redo.log.consumer.ssl.truststore.password: |
      ${file:/mnt/sslcerts/tls-connect/jksPassword.txt:jksPassword}
    redo.log.consumer.sasl.mechanism: OAUTHBEARER
    redo.log.consumer.sasl.login.callback.handler.class: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
    redo.log.consumer.sasl.jaas.config: |
      org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required metadataServerUrls="https://kafka:8090" username="${file:/mnt/secrets/mds-connect/bearer.txt:username}" password="${file:/mnt/secrets/mds-connect/bearer.txt:password}";
    redo.log.topic.name: ${connectorName}-redo-log
    redo.log.corruption.topic: redo-log-corruption-topic
    table.inclusion.regex: |
      ORCLPDB1[.].*[.](CUSTOMERS|REGIONS|COUNTRIES)

    connection.pool.connection.wait.timeout.ms: "120000"
    connection.pool.initial.size: "0"
    connection.pool.login.timeout.ms: "30000"
    connection.pool.max.size: "20"
    connection.pool.min.size: "0"
    db.timezone: UTC
    emit.tombstone.on.delete: "true"
    enable.metrics.collection: "true"
    topic.creation.redo.include: .*-redo-log
    topic.creation.redo.replication.factor: "1"
    topic.creation.redo.partitions: "1"
    topic.creation.redo.cleanup.policy": delete
    topic.creation.redo.retention.ms": "1209600000"
    topic.creation.default.replication.factor: "2"
    topic.creation.default.partitions: "1"
    topic.creation.default.cleanup.policy: delete
    behavior.on.unparsable.statement: fail
    behavior.on.dictionary.mismatch: log
    enable.metric.collection: "true"
#    snapshot.threads.per.task: 4
    errors.log.enable: "true"
    errors.log.include.messages: "true"
    errors.retry.delay.max.ms: "60000"
    errors.retry.timeout: "60000"
    errors.tolerance: none
    exactly.once.support: requested
    query.timeout.ms: "300000"
    max.retry.time.ms: "86400000"
#    key.template: ${primaryKeyStructOrValue}
#    log.sensitive.data: "true"
    max.batch.size: "1000"
    max.batch.timeout.ms: "5000"
    max.buffer.size: "0"
    numeric.default.scale: "127"
    connection.pool.inactive.timeout.ms: "60000"
    connection.pool.check.interval.timeout.ms: "30000"
    connection.pool.property.cycle.interval.ms: "30000"


    transaction.boundary.interval.ms: "10000"
    transaction.boundary: poll
    use.transaction.begin.for.mining.session: "true"
    record.buffer.mode: connector

